[["index.html", "Prácticas de Ecología de Sistemas Acuáticos ¿Cómo seguir la práctica?", " Prácticas de Ecología de Sistemas Acuáticos Jorge Juan Montes Pérez (jmontesp@uma.es) ¿Cómo seguir la práctica? Este documento está editado con bookdown. Lo podéis leer directamente en html (recomendado) o descargarlo tanto en formato pdf como en formato mobi. En la parte superior, encontraréis un icono para desplegar u ocultar la tabla de contenidos, un icono para buscar dentro del documento,un icono para descargar los formatos pdf y mobi y varios icono para compartir a través de distintas plataformas. A lo largo del documento entraréis “trocitos” de código R. Si pincháis en el recuadro code se desplegará todo el código y os aparecerá un icono para copiarlo. De esta manera, podréis ir copiando el código a vuestro script de R e ir siguiendo cada paso de la práctica. Prácticas Ecología de Sistemas Acuáticos by Jorge Juan Montes Pérez is licensed under a Creative Commons Reconocimiento-NoComercial 4.0 Internacional License. "],["introducción.html", "1 Introducción", " 1 Introducción Debido al gran avance tecnológico de los últimos años, se ha conseguido una amplia variedad de dispositivos que permiten registrar una ingente cantidad de información con relativamente poco esfuerzo. Un ejemplo de esto, son los dispositivos que registran información de variables de interés (Ej: temperatura, humedad, irradiancia) a un determinado intervalo de tiempo y de manera autónoma. Muchos de estos dispositivos pueden ser instalados en lugares remotos y transmitir la información telemáticamente o almacenarla en la memoria interna. Esto a supuesto un gran avance en el campo de la ecología acuática1. Cómo podéis imaginar, estos dispositivos han permitido obtener una gran cantidad de información con una resolución temporal (de incluso minutos o segundos) y durante grandes periodos de tiempo (meses/años) que sería impracticable mediante los métodos tradicionales. Figura 1.1: Sistemas de monitoreo de alta frecuencia. Izquierda: boya flotante que realiza medidas cada 10 minutos a una profundidas de 1.5 metros en el embalse de Sau (Barcelona). Derecha: boya flotante que realiza perfiles verticales desde la superficie hasta el fondo con un resolución espacial de 1 metro y una resolución temporal de 2 horas en el embalse de El Gergal (Sevilla). Los monitoreos de alta frecuencia (HFM) tienen muchas aplicaciones dentro de la ecología acuática, tanto en el ámbito de la gestión como de la investigación. Por ejemplo, pueden ser usados para controlar la calidad del agua en un embalse que suministra agua potable a una ciudad, control de vertidos de una industria, estudiar el efecto de eutrofización en un lago de alta montaña o detectar cambios en las corrientes marinas. Sin embargo, no todo es de color de rosas. Imaginaos que, después de dos años, vamos a recoger la información que ha almacenado nuestro sensor de temperatura y oxígeno disuelto que dejamos colocado en el centro de un lago de los pirineos. Al descargar la información, nos encontramos que tenemos 1.036.800 registros (porque claro está, queríamos registrar los datos cada segundo)… Echamos manos mano de nuestro amado Excel (Calc para los radicales del software libre) e intentamos calcular la temperatura media de esos dos años entre las 00:00 a las 08:00. A mí me ha entrado un sudor frío. Y es que, esta vasta y valiosa información tiene un inconveniente… tenemos que trabajar con miles o millones de datos. Por suerte, se disponen de muchas herramientas para trabajar con los datos. En esta práctica de Ecología de Sistemas Acuáticos, en la que vamos a trabajar con datos de HFM para estudiar la estructura térmica de un lago, me gustaría presentaros una herramienta, que a mi parecer, es fundamental para cualquier biólog@ y que os permitirá realizar todo el trabajo (desde organización de la información hasta su visualización, pasando por el análisis estadístico) con un solo software libre, de código abierto y gratuito. Estamos hablando de R. Para l@s que no lo conozcáis, Si buscáis R en google os aparecerá en las primera 4-5 entradas. Esto nos puede dar una idea de su relevancia a nivel mundial. A partir de aquí, no os voy a engañar, R no es, por lo general, muy agradable y no suele despertar simpatías. ¡Echad un vistazo a la figura de abajo! Figura 1.2: Comparación de la curva de aprendizaje de distintos software estadísticos. Fuente: https://twitter.com/rogierK/status/730863729420701697 Sin embargo, cuando esos momentos de flaqueza acontezcan imaginad si sería posible hacerlo con otra herramienta y el tiempo que os llevaría. Además, cada vez que tengáis que hacer un estudio o evaluación necesitaréis usar Excel para ordenar los datos, SPSS (u otro programa de estadística) para el análisis y sigma plot (o similar) para hacer gráficas decentes. Mejor no hablamos de software específicos para cada campo: VENSIM, PRIME, Ocean Data View, SURFER, etc. A la larga el tiempo invertido habrá merecido la pena. Por supuesto, esto ha revolucionado infinidad de campos como la biomedicina, ingeniería, informática, meteorología, etc↩︎ "],["estructura-de-la-práctica.html", "2 Estructura de la práctica", " 2 Estructura de la práctica Obtener los datos con los que vamos a trabajar. Usaremos la red The Global Lake Ecological Observatory Network (GLEON). Esta red pone a nuestra disposición una amplia cantidad de datos de monitoreo de alta frecuencia (HFM) de distintos lugares del mundo. Primeros pasos en R. Familiarizarnos con los paquetes y funciones básicos de R que nos permiten explorar y trabajar con grandes tablas de datos. Calcular profundidad de la termoclina y la estabilidad de la columna de agua (número de Smidch) usando el paquete de R rLakeAnalyzer. Gráficas de contorno. "],["Descarga.html", "3 Descargar los datos de la red GLEON", " 3 Descargar los datos de la red GLEON Para ello, visitamos la página de la red GLEON y nos vamos al apartado de datos. En esta sección podemos encontrar la política de datos de GLEON, básicamente se apuesta por una ciencia colaborativa en la que los datos quedan a disposición de la comunidad para cualquier fin de investigación, académico, educativo o cualquier otro, siempre que no haya un interés lucrativo detrás y respetando algunos principios de comunicación con los responsables de los datos. Como se muestra en esta sección, a los datos de GLEON se puede acceder a través de tres buscadores EDI, DataONE o Google data set. Pues bien, para este práctica vamos a trabajar, en concreto, con datos del lago Crystal. Así que utilizando el buscador que más sea de vuestro agrado lanzamos la siguiente búsqueda: crystal lake. Entre los resultados obtenidos (hay bastante información como podéis observar), vamos a seleccionar los datos derivados del proyecto North Temperate Lakes Long Term Ecologycal Research (NTL-LTER) que nos ofrecen datos de temperatura, oxígeno disuelto, clorofila a y pH desde 2011 hasta 2014. Si no pudierais encontrarlos, podéis pinchar aquí: North Temperate Lakes LTER High Frequency Water Temperature Data, Dissolved Oxygen, Chlorophyll, pH - Crystal Lake 2011 - 2014. En esa página que acabáis de abrir tenéis un sumario con toda la información necesario sobre el paquete de datos (Title, Creators, Publication Date, Citation, Abstract, Spatial Coverage, Package ID, Resources, Intellectual Rights, Digital Object Identifier, PASTA Identifier, Code Generation, Provenance, Journal Citations). Las que más nos van a interesar por el momento son Abstract, Resources y Code Generation. La primera de ellas es un resumen que nos explica como han sido recogido los datos y algunas particularidades que debemos saber, en la segunda tenemos directamente los archivos con los datos para descargarlos en formato *.csv y una opción muy interesante, View Full Metadata, en la que si desplegamos Data Entities podemos ver información sobre las variables que aparecen en la tabla de datos como, por ejemplo, las unidades en las que están medidas. En este caso, disponemos solo de un fichero. Para descargar los datos tenemos dos opciones: Podemos pinchar directamente en el archivo y descargarlo a través del navegador. Name: High Resolution Water Temperature Dissolved Oxygen Chlorophyll pH - Crystal Lake File: ntl303_v1_0.csv (120.5 MiB; 22 downloads). Si optamos por esta opción, posteriormente habrá que importar los datos a R. Otra opción mucho más cómoda es la de usar un script de R que ya nos han preparado para facilitarnos la descarga e importación. Para ello, tenemos dos opciones también: Pinchamos en el icono de R en el apartado Code Generation. Pinchamos en la opción tidyr en el apartado Code Generation. Os recomiendo usar esta última, es la que vemos más abajo y, además, si no lo tenemos instalado, instala automáticamente el paquete Tidyverse. Tidyverse es en realidad un conjunto de paquetes de R especialmente diseñado para la ciencia de datos que nos vendrá de maravilla para esta práctica. Independientemente por cual os decantéis, debéis abrir el archivo pinchando en File Download: knb-lter-ntl.303.20.r o File Download: knb-lter-ntl.303.20.tidyr y se abrirá automáticamente con R, si no es así, lo descargáis y lo abrís posteriormente con R. Una vez abierto ya podéis ejecutar el script (Ctrl+A y después Crtl+Enter). Como veis también hay opción para descargar y trabajar directamente los datos con otras herramientas, si a alguno le pica la curiosidad ¡adelante!. En esta práctica como hemos dicho vamos a usar R, debido a que es una herramienta gratuita, de código abierto y libre. Además es ampliamente usado en investigación debido a su naturaleza libre y colaborativa. En fin, si más dilaciones, podéis descargar el script, abrirlo con RStudio y ejecutarlo ¡A ver qué pasa!. Esta es la pinta que tiene el script: # Package ID: knb-lter-ntl.303.20 Cataloging System:https://pasta.edirepository.org. # Data set title: North Temperate Lakes LTER High Frequency Water Temperature Data, Dissolved Oxygen, Chlorophyll, pH - Crystal Lake 2011 - 2014. # Data set creator: John Magnuson - University of Wisconsin # Data set creator: Stephen Carpenter - University of Wisconsin # Data set creator: Emily Stanley - University of Wisconsin # Data set creator: NTL Lead PI - University of Wisconsin # Metadata Provider: NTL Information Manager - University of Wisconsin # Contact: NTL Information Manager - University of Wisconsin - ntl.infomgr@gmail.com # Contact: NTL Lead PI - University of Wisconsin - ntl.leadpi@gmail.com # Stylesheet for metadata conversion into program: John H. Porter, Univ. Virginia, jporter@Virginia.edu # #install package tidyverse if not already installed if(!require(tidyverse)){ install.packages(&quot;tidyverse&quot;) } library(&quot;tidyverse&quot;) infile1 &lt;- trimws(&quot;https://pasta.lternet.edu/package/data/eml/knb-lter-ntl/303/20/b9b3b932deec8f3e71fb8d70cacf6a0e&quot;) infile1 &lt;-sub(&quot;^https&quot;,&quot;http&quot;,infile1) # This creates a tibble named: dt1 dt1 &lt;-read_delim(infile1 ,delim=&quot;,&quot; ,skip=1 , col_names=c( &quot;sampledate&quot;, &quot;year4&quot;, &quot;daynum&quot;, &quot;sample_time&quot;, &quot;depth_calculated&quot;, &quot;wtaer_temp&quot;, &quot;flag_water_temp&quot;, &quot;pH&quot;, &quot;flag_ph&quot;, &quot;chlorophylla&quot;, &quot;flag_chlorophylla&quot;, &quot;opt_do2&quot;, &quot;flag_do2&quot;, &quot;opt_dosat_raw&quot;, &quot;flag_opt_dosat_raw&quot; ), col_types=list( col_character(), col_number() , col_number() , col_character(), col_number() , col_number() , col_character(), col_number() , col_character(), col_number() , col_character(), col_number() , col_character(), col_number() , col_character()), na=c(&quot; &quot;,&quot;.&quot;,&quot;NA&quot;) ) # Observed issues when reading the data. An empty list is good! problems(dt1) # Here is the structure of the input data tibble: glimpse(dt1) # And some statistical summaries of the data summary(dt1) # Get more details on character variables summary(as.factor(dt1$flag_water_temp)) summary(as.factor(dt1$flag_ph)) summary(as.factor(dt1$flag_chlorophylla)) summary(as.factor(dt1$flag_do2)) summary(as.factor(dt1$flag_opt_dosat_raw)) Esta primera parte del script es para descargar los datos (igual que arriba, salvo que me he tomado el tiempo de comentar algunas líneas): # Package ID: knb-lter-ntl.303.20 Cataloging System:https://pasta.edirepository.org. # Data set title: North Temperate Lakes LTER High Frequency Water Temperature Data, Dissolved Oxygen, Chlorophyll, pH - Crystal Lake 2011 - 2014. # Data set creator: John Magnuson - University of Wisconsin # Data set creator: Stephen Carpenter - University of Wisconsin # Data set creator: Emily Stanley - University of Wisconsin # Data set creator: NTL Lead PI - University of Wisconsin # Metadata Provider: NTL Information Manager - University of Wisconsin # Contact: NTL Information Manager - University of Wisconsin - ntl.infomgr@gmail.com # Contact: NTL Lead PI - University of Wisconsin - ntl.leadpi@gmail.com # Stylesheet for metadata conversion into program: John H. Porter, Univ. Virginia, jporter@Virginia.edu # #install package tidyverse if not already installed. Aquí cargamos el conjunto de paquetes que están dentro de &quot;tidyverse&quot; y si no lo tuvieramos instaldo, han pensado en nosotros y, se instala solo. if(!require(tidyverse)){ install.packages(&quot;tidyverse&quot;) } library(&quot;tidyverse&quot;) infile1 &lt;- trimws(&quot;https://pasta.lternet.edu/package/data/eml/knb-lter-ntl/303/20/b9b3b932deec8f3e71fb8d70cacf6a0e&quot;) #Esta, de arriba, es la dirección de donde descarga los datos infile1 &lt;-sub(&quot;^https&quot;,&quot;http&quot;,infile1) # This creates a tibble named: dt1 dt1 &lt;-read_delim(infile1 #Crea un objeto donde descarga los datos de la dirección que le damos, guardada en el objeto con nombre &quot;infile1&quot; ,delim=&quot;,&quot; ,skip=1 , col_names=c( #Asigna nombre a las columnas &quot;sampledate&quot;, &quot;year4&quot;, &quot;daynum&quot;, &quot;sample_time&quot;, &quot;depth_calculated&quot;, &quot;wtaer_temp&quot;, &quot;flag_water_temp&quot;, &quot;pH&quot;, &quot;flag_ph&quot;, &quot;chlorophylla&quot;, &quot;flag_chlorophylla&quot;, &quot;opt_do2&quot;, &quot;flag_do2&quot;, &quot;opt_dosat_raw&quot;, &quot;flag_opt_dosat_raw&quot; ), col_types=list( col_character(), col_number() , col_number() , col_character(), col_number() , col_number() , col_character(), col_number() , col_character(), col_number() , col_character(), col_number() , col_character(), col_number() , col_character()), na=c(&quot; &quot;,&quot;.&quot;,&quot;NA&quot;) ) Este trocito de código que sigue es para corregir algún problema de formato que se haya podido introducir debido a algún error en la base de datos. # Observed issues when reading the data. An empty list is good! problems(dt1) Este último trozo es simplemente para ver la estructura de los datos y un resumen de cada una de la variables. Este trozo no es necesario que lo ejecutéis. # Here is the structure of the input data tibble: glimpse(dt1) # And some statistical summaries of the data summary(dt1) # Get more details on character variables summary(as.factor(dt1$flag_water_temp)) summary(as.factor(dt1$flag_ph)) summary(as.factor(dt1$flag_chlorophylla)) summary(as.factor(dt1$flag_do2)) summary(as.factor(dt1$flag_opt_dosat_raw)) Bien, una vez ejecutado el script, ya debemos tener los datos en nuestro entorno de RStudio en un tipo de objeto denominado data.frame (básicamente una tabla de datos). Vamos a ver que pinta tienen: head(dt1) Por último, los vamos a guardar en la carpeta “Datos” que hemos creado. write.csv(dt1, &quot;./Datos/Datos_Crystal.csv&quot;, row.names = FALSE) "],["PrimerosPasos.html", "4 Primero pasos 4.1 Ejercicios", " 4 Primero pasos A estas alturas es posible que ya se haya generado una histeria colectiva. A la mayoría de vosotr@s ya os habrá dado algún error y, a l@s que no, esa cantidad de código ininteligible os habrá quitado las ganas de vivir. ¡Que no cunda el pánico! Vamos a ver alguna nociones básicas sobre R. Si os preguntáis porqué ahora y no antes: porque hasta que no surgen las dudas, no tiene sentido dar las respuestas. Figura 4.1: Interfaz de R. RStudio es una IDE (entorno de desarrollo integrado) para R. En román paladino, RStudio nos permite usar R de una manera más intuitiva y con muchas herramientas que nos facilitan la vida. Como vamos usar RStudio para comunicarnos con R, cada vez que hablemos de R vamos a referirnos indistintamente a R y a RStudio. Bien, pues en la imagen de arriba vemos 4 subventanas. Veamos una a una: Figura 4.2: Scripts en R. En esta ventana se muestra el script. El script no es, ni más ni menos, que una hoja donde vamos escribiendo todas las ordenes que le queremos dar a R. Nos permite ir guardando todo lo que hacemos, modificar sobre lo que ya hemos hecho, ejecutar sólo la parte que nos interesa y organizar la información. Vamos a escribir nuestra primera línea en R, usándolo como una simple calculadora (pincha sobre el recuadro code para ver el código): 2+2 ## [1] 4 Si escribís 2+2 y pulsáis Ctrl+Enter se ejecuta solo la línea en la que estamos. Veréis que el resultado (4) os aparece en la ventana consola: Figura 4.3: Consola R. Como podéis intuir la consola es donde tiene lugar la parte importante. En ella se ejecutan las ordenes, nos informa de los errores y nos devuelve la información que le pedimos. Volvamos al script. R es una lenguaje orientado a objetos, esto se traduce en que vamos a ir guardando la información en “objetos” virtuales y vamos a trabajar con estos objetos. Siguiente el ejemplo anterior, vamos a crear nuestros primeros objetos: x &lt;- 2 y &lt;- 2 Hemos creado dos objetos, una llamado x y otro llamado y. Ambos guardan la información del valor 2. Además, si os habéis fijado, en la ventana superior derecha os han aparecido esos dos objetos: Figura 4.4: Ventana Environment. En esta ventana aparecerán todos los objetos que hemos creado durante nuestra sesión de trabajo. Ahora vamos a sumar estos dos objetos: x+y ## [1] 4 ¡Enhorabuena! ya habéis creado vuestros primeros objetos en R y habéis trabajado con ellos. Ahora vamos a sacarle más partido a esto. Como imaginaréis, en un objeto de R se puede almacenar muchas más información que un sólo número. Vamos a imaginar que tenemos información sobre la temperatura del agua medida en distintos sistemas epicontinentales y queremos guardar esa información en un objeto llamado Temperatura: Temperatura &lt;- c(23, 23.5, 20, 25) Ahora vamos a calcular la temperatura media y su desviación: mean(Temperatura) ## [1] 22.875 sd(Temperatura) ## [1] 2.096624 ¡Ojo! R es muy quisquilloso y si no le dais el nombre exacto de Temperatura (incluyendo mayúsculas y minúsculas) no os entenderá y os devolverá un error. Por lo tanto, sed muy cuidadosos con la sintaxis y revisad que todo está escrito correctamente (que no falte ningún paréntesis o corchete). En estas últimas líneas han sucedido un par de cosas: hemos creado un objeto nuevo, un vector, y hemos usado dos funciones mean() y sd() que calculan la media y desviación estándar. Un vector almacena información de un mismo tipo, en este caso numérico. Existen distintos tipos de vector en función de la información que almacén: Numérico: almacenan números. Carácter: almacenan texto. Factores: almacenan factores, generalmente texto pero que usaremos como un tratamiento en el análisis. Fechas: almacenan fechas en distintos formatos. En cuanto a las funciones, existen infinidad de ellas. R trae muchas funciones básicas pero si queremos aplicar funciones más especificas necesitaremos instalar paquetes que han sido creados específicamente para ello. La estructura genérica de una función sería. nombre_funcion(x = objeto_donde_aplicarla, argumento1 = &quot;valor1&quot;, argumento2 = &quot;valor2&quot;) Si queremos obtener más información sobre una función y su uso podéis usar la función help(\"funcion_que_os_interesa\") o más cómodo ?funcion_que_os_interesa: ?mean Veréis que se os abrirá la última ventana que nos quedaba por ver: Figura 4.5: Ayuda en RStudio Aquí encontréis la información necesaria para usar la función así como algunos ejemplos. Por último, vamos a ver otro objeto muy útil: data.frame. Un data.frame no es más que una tabla de datos, como la que acostumbráis a hacer en Excel. Veamos un ejemplo: Ya tenemos la temperatura del agua que se ha registrado en distintos sistemas epicontinentales (Temperatura). Ahora nos dan la información del tipo de sistema y queremos crear un tabla que recoja toda la información: Temperatura &lt;- c(23, 23.5, 20, 25) Sistemas &lt;- c(&quot;Lago&quot;, &quot;Lago&quot;, &quot;Rio&quot;, &quot;Rio&quot;) #Creamos un vector esta vez de tipo caracter (el texto va entre comillas) Temperatura_en_distintos_sistemas &lt;- data.frame(Temperatura, Sistemas) View(Temperatura_en_distintos_sistemas) #La función View() nos muestra el objeto que deseemos. Se os abrirá una ventana con la información recogida en el data.frame Temperatura_en_distintos_sistemas. En este último trozo de código habéis visto un elemento nuevo: comentarios. Es altamente recomendado comentar el código que estamos escribiendo. De este modo, será mucho más claro y cuando vuelvas a abrir el script después de meses “tu yo del futuro” te lo agradecerá. Además si queréis compartir código con otr@s compañer@s es necesario añadir comentarios para que sepan que hacemos en cada sección. Para comentar, como habéis visto, sólo hay que añadir # delante del texto y este no se ejecutará. Si no ponéis # R lo entenderá como una orden y os dará error. Otra cosa que habréis podido notar es que, aunque R nos ayuda autocompletando la frase, el nombre Temperatura_en_distintos_sistemas no es muy funcional que se diga. Es más práctico usar nombres cortos, pero nos indiquen claramente de que se trata, a la hora de nombrar objetos en R. A la hora de nombrar objetos en R hay algunas nombres que debemos respetar. Los nombres no pueden ser números o empezar con número. No podríamos usar 1 ó 2 ni 2datos, pero sí podríamos usar datos2. No se usar caracteres especiales: #, !, @, etc. Los espacios tampoco pueden ser usado dentro de los nombres. Usar en su lugar mayúsculas ó barra baja. Por ejemplo, usar DatosLagos o Datos_lagos en lugar de Datos lagos. Temperatura &lt;- c(23, 23.5, 20, 25) Sistemas &lt;- c(&quot;Lago&quot;, &quot;Lago&quot;, &quot;Rio&quot;, &quot;Rio&quot;) #Creamos un vector esta vez de tipo caracter (el texto va entre comillas) Temp_sistemas &lt;- data.frame(Temperatura, Sistemas) View(Temperatura_en_distintos_sistemas) #La función View() nos muestra el objeto que deseemos. ¡Genial! Ya hemos visto los objetos básicos. Irán saliendo más a lo largo de la práctica, pero por ahora es suficiente. 4.1 Ejercicios ¿Qué sucede si corremos Sistemas[2]? Prueba con distintos números. ¿Y si corremos Temp_sistemas[2]? Da error… prueba Temp_sistemas[,2] ¿Y si ponemos un número delante de la ,? ¿Que indican los números que van delante de la coma y los que van detrás? Además de la temperatura se midió el pH: 7.8, 7.5, 9 y 8.5. Incluye estos valores en el data.frame Temp_sistemas. Hazlo con los conocimientos que tienes y luego prueba con la función cbind(). Nos dan también la concentración de clorofila a, pero en este caso falta un dato y lo rellenamos con NA, que significa que no está disponible. Cla &lt;- c(15.6, NA, 3, 4). Calcula la concentración de clorofila media. Recuerda, cuando tengas dudas sobre como utilizar una función: ?mean. "],["Tidyverse.html", "5 Paquetes importantes y sus funciones básicas 5.1 Importar datos 5.2 Organizar tablas 5.3 Gráficas 5.4 Trabajar con fechas", " 5 Paquetes importantes y sus funciones básicas Ya hemos dado nuestros primeros pasos en R, conocemos su entorno RStudio, hemos creado nuestros primeros objetos y aplicado un par de funciones básicas. Ahora vamos a dar un paso más allá y vamos a ver algunos de lo más paquetes que pueden ser más importantes para nosotros y sus funciones más útiles. Para esta parte de la práctica ya debemos haber descargado los datos de la plataforma GLEON como se indicó en la sección 3. Lo primero que nos preguntaremos, ¿Qué es un paquete? Un paquete de R es un conjunto de funciones que han sido creadas con un objetivo común, por ejemplo hacer gráficas, y que han sido agrupadas para que puedan ser cargadas en R todas juntas. Para instalar un paquete no tenemos mas que ejecutar: install.packages(&quot;nombre_del_paquete&quot;) 5.1 Importar datos La mayoría de los paquetes que vamos a ver durante la práctica han sido agrupados en una colección de paquetes que nos permite instalarlos y cargarlos todos juntos. Esta colección de paquetes se llama tidyverse. El primer paquete que vamos a ver es readr. Si aún no hemos instalado tydiverse: install.packages(&quot;tidyverse&quot;) Si ya lo tenemos instalado, solo tenemos que “llamarlo” o cargarlo. Cada vez que abrimos una sesión de R hay que cargar los paquetes que vayamos a usar durante la sesión. No es necesario volver a instalarlos pero sí hay que cargarlos usando la función library(): #Library. Al principio de nuestro scrip creamos un apartado donde iremos cargando los paquetes nos irán haciendo falta. library(readr) #Si solo quisieramos cargar el paquete readr. #Library. Al principio de nuestro scrip creamos un apartado donde iremos cargando los paquetes nos irán haciendo falta. library(tidyverse) #De esta forma, todos los paquetes que agrupa tydiverse: ggplot2, readr, dplyr, etc. Yo usaría esta. ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ── ## ✓ ggplot2 3.3.2 ✓ purrr 0.3.4 ## ✓ tibble 3.0.4 ✓ dplyr 1.0.2 ## ✓ tidyr 1.1.2 ✓ stringr 1.4.0 ## ✓ readr 1.4.0 ✓ forcats 0.5.0 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() Vemos que al cargar tydiverse nos informa de qué paquetes han sido cargados y algunas funciones que tienen conflicto con otros paquetes. Una vez cargado el paquete, la primera función que vamos a necesitar es read_csv(). Esta función nos permite importar tablas que se han guardado en formato .csv. Al principio de la práctica, creamos un proyecto de R, descargamos los datos de la plataforma y los guardamos en la carpeta Datos de nuestro directorio. Si guardasteis vuestro espacio de trabajo al salir, tendréis un objeto llamado dt1. Pero si no guardasteis, tendremos que importar los datos de nuevo y, además, aprovechamos para ponerle un nombre que nos sea más evocador que dt1, usaremos, por ejemplo, Crystal: Crystal &lt;- read_csv(&quot;Datos/Datos_Crystal.csv&quot;) ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## sampledate = col_datetime(format = &quot;&quot;), ## year4 = col_double(), ## daynum = col_double(), ## sample_time = col_double(), ## depth_calculated = col_double(), ## wtaer_temp = col_double(), ## flag_water_temp = col_logical(), ## pH = col_double(), ## flag_ph = col_logical(), ## chlorophylla = col_double(), ## flag_chlorophylla = col_character(), ## opt_do2 = col_double(), ## flag_do2 = col_logical(), ## opt_dosat_raw = col_double(), ## flag_opt_dosat_raw = col_logical() ## ) ## Warning: 10065 parsing failures. ## row col expected actual file ## 41821 flag_opt_dosat_raw 1/0/T/F/TRUE/FALSE C &#39;Datos/Datos_Crystal.csv&#39; ## 41822 flag_opt_dosat_raw 1/0/T/F/TRUE/FALSE C &#39;Datos/Datos_Crystal.csv&#39; ## 41823 flag_opt_dosat_raw 1/0/T/F/TRUE/FALSE C &#39;Datos/Datos_Crystal.csv&#39; ## 41824 flag_opt_dosat_raw 1/0/T/F/TRUE/FALSE C &#39;Datos/Datos_Crystal.csv&#39; ## 41825 flag_opt_dosat_raw 1/0/T/F/TRUE/FALSE C &#39;Datos/Datos_Crystal.csv&#39; ## ..... .................. .................. ...... ......................... ## See problems(...) for more details. Al importar el archivo, la función reconoce automáticamente el tipo de elementos que se guarda en cada columna. Por ejemplo, la columna sampledate es de tipo fecha, mientras que year y depth_calculated son doubles que vienen a ser valores numéricos no enteros (double no es más que la forma en la que ese número se expresa en forma binaria usando 64 bits). No os preocupéis por el aviso (warnings) que nos da, nos avisa de que esperaba encontrar un tipo de valor en una columna que no se corresponde con lo que ha entrado. A nosotros no nos preocupa la información que hay en esa columna.2 Vamos a ver un resumen de la información que tenemos disponible en la tabla de datos. #Vistazo general summary(Crystal) ## sampledate year4 daynum sample_time ## Min. :2011-04-29 17:54:00 Min. :2011 Min. : 82.0 Min. : 0 ## 1st Qu.:2011-10-30 02:06:45 1st Qu.:2011 1st Qu.:161.0 1st Qu.: 600 ## Median :2012-09-26 16:19:30 Median :2012 Median :208.0 Median :1203 ## Mean :2013-01-11 09:27:48 Mean :2012 Mean :209.3 Mean :1183 ## 3rd Qu.:2013-11-08 16:38:15 3rd Qu.:2013 3rd Qu.:257.0 3rd Qu.:1803 ## Max. :2014-11-04 06:42:00 Max. :2014 Max. :323.0 Max. :2359 ## NA&#39;s :758072 ## depth_calculated wtaer_temp flag_water_temp pH ## Min. : 0.000 Min. : 0.00 Mode:logical Min. : 0.000 ## 1st Qu.: 1.000 1st Qu.: 9.79 NA&#39;s:1049068 1st Qu.: 7.390 ## Median : 1.000 Median :16.77 Median : 7.930 ## Mean : 4.316 Mean :15.76 Mean : 8.028 ## 3rd Qu.: 7.000 3rd Qu.:21.32 3rd Qu.: 8.660 ## Max. :19.000 Max. :27.41 Max. :12.020 ## ## flag_ph chlorophylla flag_chlorophylla opt_do2 ## Mode:logical Min. : 0.00 Length:1049068 Min. : 0.000 ## NA&#39;s:1049068 1st Qu.: 1.59 Class :character 1st Qu.: 8.230 ## Median : 2.45 Mode :character Median : 8.810 ## Mean : 2.87 Mean : 8.737 ## 3rd Qu.: 3.57 3rd Qu.: 9.840 ## Max. :10.00 Max. :15.690 ## NA&#39;s :76577 ## flag_do2 opt_dosat_raw flag_opt_dosat_raw ## Mode:logical Min. : 1.00 Mode:logical ## NA&#39;s:1049068 1st Qu.: 90.30 NA&#39;s:1049068 ## Median :100.50 ## Mean : 94.27 ## 3rd Qu.:104.60 ## Max. :148.50 ## NA&#39;s :10065 R nos muestra para cada columna los valores mínimos, máximos, la media, la mediana y los cuartiles 1 y 3. Además, también nos dice cuantos valores faltan (NA’s). Recordad que podéis usar la función View() para ver los datos directamente, también podéis hacer doble click sobre el objeto dt1. 5.2 Organizar tablas Una cosa está clara, tenemos mucha información y, además, el archivo es bastante pesado, casi 140 MB. Vamos a centrarnos sólo en un año, 2012 por ejemplo. Para ello vamos a tirar mano de otro paquete: dplyr. Este es otro de los que ya viene preparado con tidyverse, por lo que tendremos que cargarlo. Este paquete es muy útil para organizar, filtrar y transformar la información de las tablas, aquí os dejo un “chuleta” con las funciones principales: chuleta dplyr. Como queremos filtrar los datos y quedarnos solo con los del año 2012, vamos a usar la función filter(). #Nos quedamos sólo con los datos del 2012 Crystal_2012 &lt;- filter(Crystal, year4 == 2012) rm(Crystal) #Aprovechamos para eliminar el otro objeto que no nos va a servir. Además, si no os fijasteis antes, el nombre de la columna que recoge la temperatura del agua está mal escrito, pone wtaer_temp en lugar de water_temp, como cabría esperar. Vamos a cambiárselo usando el paquete dplyr. Crystal_2012 &lt;- rename(Crystal_2012, water_temp = wtaer_temp) 5.2.1 Ejercicios: Filtra la tabla para quedarte con los datos del 2013. Filtra la tabla para quedarte solo con los datos que fueron tomados a un metro de profundidad. 5.3 Gráficas ¡Perfecto! Ahora vamos a hacer alguna gráfica. Para ello vamos a usar otro paquete, también incluido en tidyverse, ggplot2. Aquí os dejo otra chuleta para usar este paquete (pincha aquí). ¿Habrá cambios en la temperatura del agua a lo largo del año? Echemos un vistazo: ggplot(Crystal_2012, aes(x = sampledate, y= water_temp))+ #Aquí indicamos donde está la información que queremos representar (Crystal_2012) y que variables x e y geom_point() #Aquí indicamos el tipo de gráfico, en este caso hemos elegido puntos Ummm… El gráfico es un poco extraño. ¿Y si seleccionamos sólo la temperatura que tenemos a 1 metro de profundidad? Crystal_temp_1m &lt;- filter(Crystal_2012, depth_calculated == 1) ggplot(Crystal_temp_1m, aes(x = sampledate, y= water_temp))+ geom_point() Algo mejor. Vemos que la temperatura aumenta durante la primavera y que vuelve a caer cuando se entra en el otoño. Sin embargo, a parte del patrón general, se puede observar un patrón secundario. Quizás se deba a oscilaciones diarias. Para ver eso tenemos que seleccionar la temperatura a la profundidad de 1 metros y un solo día. Con la función filter podemos hacer eso. Temp_1m_1dia &lt;- filter(Crystal_2012, depth_calculated == 1 &amp; daynum == 260) #Yo he elegido el día 260 (16 de septiembre) ggplot(Temp_1m_1dia, aes(x=sampledate, y = water_temp))+ geom_point() Parece que sí, como cabría esperar la temperatura baja por la noche y sube por el día. Además hemos aprendido una cosa nueva en R: los operadores. Os dejo los más comunes: Operador Descripción &gt; mayor que &lt; menor que &gt;= mayor o igual que &lt;= menor o igual que == exactamente igual que != distinto a x &amp; y x e y x | y x o y Ahora, vamos a hacer algunos arreglos estéticos (cambiar el nombre de los ejes, el fondo) ggplot(Temp_1m_1dia, aes(x = sampledate, y= water_temp))+ #Aquí indicamos donde está la información que queremos representar (Crystal_2012) y qué variables x e y geom_point()+ #Aquí indicamos el tipo de gráfico, en este caso hemos elegido puntos labs(x = &quot;Fecha&quot;, y = &quot;Temperatura&quot;, title = &quot;Temperatura a 1 m de profundidad&quot;)+ #Aquí podemos modificar las etiquetas del gráfico. theme_classic() #Esta función usa un &quot;tema&quot; predefinido para la gráfica Ya tiene mejor pinta. Vamos a ver si se comporta igual a distinta profundidad. Para ello, solo tenemos que decirle a ggplot que nos haga una gráfica por cada profundidad usando facet_wrap(). Crystal_temp_dia260 &lt;- filter(Crystal_2012, daynum == 260) ggplot(Crystal_temp_dia260, aes(x = sampledate, y= water_temp))+ #Aquí indicamos donde está la información que queremos representar (Crystal_2012) y que variables x e y geom_point()+ #Aquí indicamos el tipo de gráfico, en este caso hemos elegido puntos labs(x = &quot;Fecha&quot;, y = &quot;Temperatura&quot;, title = &quot;Temperatura a 1 m de profundidad&quot;)+ #Aquí podemos modificar las etiquetas del gráfico. facet_wrap(~depth_calculated)+ #En esta línea le indicamos que haga una gráfica por cada profundidad. scale_x_datetime(date_labels = &quot;%R&quot;)+ #He añadido esta línea para que el formato de la fecha ponga solo la hora. theme_classic() #Esta función usa un &quot;tema&quot; predefinido para la gráfica Aquí podemos ver varias cosas interesantes. Por un lado, la temperatura parece oscilar a lo largo del día (día-noche) sólo en las capas más superficiales pero en las capas profundas la variación es mínima ¿alguna idea? ¿Podría estar la masa de agua estratificada? Lo veremos más adelante… Por otro lado, vemos que la cantidad de información (puntos) no es la misma en cada profundidad, a 1 metros tenemos muchos más registros de temperatura que a 10 o 12 metros. Vamos a comprobar si es algo general para todos los días: #Contamos el número de filas que hay para cada profundidad y día Test_profundidades &lt;- Crystal_2012 %&gt;% group_by(daynum, depth_calculated) %&gt;% summarise(n_filas = n()) ## `summarise()` regrouping output by &#39;daynum&#39; (override with `.groups` argument) #Lo representamos en una gráfica ggplot(Test_profundidades, aes(x = depth_calculated, y = n_filas))+ geom_point()+ labs(x = &quot;Profundidad&quot;, y = &quot;Número de filas&quot;)+ theme_classic() Vemos que en las profundidades de 0 metros y 1 metro hay muchos más registros que en el resto. Por lo tanto, la variabilidad diaria puede no estar igual de bien recogida para todas las profundidades. En la siguiente sección vamos a seleccionar una franja horaria y a obtener un valor medio por profundidad. En el código que acabamos de ejecutar habréis encontrado algunos elementos nuevos. Tres funciones nuevas, group_by(), summarise() y n(), que nos permiten agrupar en función de las variables que queramos, resumir la información de la tabla y contar el número de elementos que hay en un grupo, respectivamente. Y un nuevo operador denominado “pipe”, %&gt;%. El operador %&gt;% nos permite concatenar funciones de una manera más fácil de visualizar. Lo vemos con un ejemplo más sencillo: #Si queremos seleccionar la variable temperatura pero sólo de la profundidad de 1 metro #Puedo hacerlo inclyendo funciones dentro de funciones: select(filter(Crystal_2012, depth_calculated == 1), daynum) ## # A tibble: 149,282 x 1 ## daynum ## &lt;dbl&gt; ## 1 82 ## 2 82 ## 3 82 ## 4 82 ## 5 82 ## 6 82 ## 7 82 ## 8 82 ## 9 82 ## 10 82 ## # … with 149,272 more rows #O concatenandolas: Crystal_2012 %&gt;% filter(depth_calculated == 1) %&gt;% select(daynum) ## # A tibble: 149,282 x 1 ## daynum ## &lt;dbl&gt; ## 1 82 ## 2 82 ## 3 82 ## 4 82 ## 5 82 ## 6 82 ## 7 82 ## 8 82 ## 9 82 ## 10 82 ## # … with 149,272 more rows Esta última es más fácil de visualizar que se está haciendo en cada paso y, por lo tanto, facilita la lectura del código. 5.3.1 Ejercicios Representa otra variable, la que a tí te apetezca. Ej: oxígeno disuelto. Prueba, en lugar de theme_classic(), otro tema diferente: por ejemplo: theme_ligth(). Prueba a usar geom_line() en lugar de geom_point(). ¿Y si en lugar de “%R” usáis “%H”? Ejecuta ?strptime y mira los formatos disponibles. Experimenta con ellos. Si ya estas muy mosquead@ con R (cosa que entiendo perfectamente), prueba a abrir la tabla con excel y repesentar la temperatura en el lago Crystal en cada profundidad para el día 260 del año 2012. ¿Cuánto tiempo te ha llevado? 5.4 Trabajar con fechas Como dijimos en la sección anterior, vamos a obtener un valor medio de temperatura por profundidad y día. Para trabajar con fechas, horas, etc. en R tenemos un paquete que nos facilita la vida: lubridate. Para este paquete también disponemos de “chuleta”, aquí os la dejo. Este paquete, aunque también se instala con tidyverse, hay que cargarlo de manera independiente. library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union En la columna sampledate tenemos recogida la información de la fecha y la hora a la que se tomó la medida. Con el paquete lubridate podemos extraer esta información de manera sencilla: date(Crystal_2012$sampledate) #Nos da la fecha hour(Crystal_2012$sampledate)#Nos da la hora minute(Crystal_2012$sampledate) #Nos da los minutos yday(Crystal_2012$sampledate) #el día del año Con esta pequeña presentación y uniendo lo que hemos visto hasta ahora, quizás, podríamos intentar calcular la temperatura media de cada profundidad para cada día teniendo en cuenta sólo los valores medidos entre las 11:00 de la mañana y las 16:00 de la tarde. Vamos a intentarlo: #nos quedamos sólo con las muestras tomadas entres las 11:00 y las 16:00 Crystal_dia &lt;- Crystal_2012 %&gt;% filter(hour(sampledate) &gt;= 11 &amp; hour(sampledate) &lt;= 16) #Calculamos la temperatura media por día y profundidad Crystal_dia %&gt;% group_by(daynum, depth_calculated) %&gt;% summarise(mean(water_temp)) ## `summarise()` regrouping output by &#39;daynum&#39; (override with `.groups` argument) ## # A tibble: 3,365 x 3 ## # Groups: daynum [189] ## daynum depth_calculated `mean(water_temp)` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 82 0 8.32 ## 2 82 1 6.54 ## 3 82 2 6.41 ## 4 82 3 5.92 ## 5 82 4 5.74 ## 6 82 5 5.66 ## 7 82 6 5.51 ## 8 82 7 5.30 ## 9 82 8 5.14 ## 10 82 9 5.03 ## # … with 3,355 more rows ¡Perfecto!¡Ya lo tenemos! Si le echáis un vistazo a la chuleta que os dejé del paquete dplyr, hay dos funciones que nos pueden resultar interesantes: between() y summarise_if(). La primera nos simplifica la vida cuando queremos filtrar dentro de un rango determinado y la segunda nos permite calcular la media de todas las variables numéricas de una vez. 5.4.1 Ejercicios Intenta aplicar la función between() para filtrar tabla y quedarnos solo con los valores que están entre las 11:00 y las 16:00. Intenta aplicar la función summarise_if() para calcular la media, no sólo de la temperatura del agua, si no de todas las variables numéricas que tenemos. Si no sabéis que información guarda esa columna, acordaos de que podéis mirar en los metadatos de la página donde descargasteis los datos.↩︎ "],["Termoclina.html", "6 Estabilidad térmica de la columna de agua 6.1 Perfil vertical 6.2 Termoclina 6.3 Capas en un lago estratificado 6.4 Estabilidad 6.5 Series temporales", " 6 Estabilidad térmica de la columna de agua Llegados a este punto de la práctica ya podemos adentrarnos en cuestiones más puramente limnológicas. Hemos echado un vistazo a los datos que descargamos y decidimos seleccionar el año 2012. Además, para el eliminar las variaciones diarias y centrarnos en una tendencia estacional, hemos obtenido un perfil promedio del lago Crystal para cada día. Si en el apartado anterior no conseguisteis hacer el promedio diario para todas las variables os dejo el código aquí para que partamos tod@s desde el mismo punto: #Library library(tidyverse) #Recordad siempre cargar los paquetes que vais a necesitar al inicio del script #Lo he recogido todo en una sola línea. Crystal_dia &lt;- Crystal_2012 %&gt;% filter(between(hour(sampledate), 11, 16)) %&gt;% group_by(daynum, depth_calculated) %&gt;% summarise_if(is.numeric, mean, na.rm = TRUE) #Exportamos los datos write_csv(Crystal_dia, &quot;Datos/Crystal_dia.csv&quot;) #Guardamos la información en un archivo 6.1 Perfil vertical Todavía no hemos visualizado lo que acabamos de hacer. Vamos a ver como ha quedado la tabla. Crystal_dia ## # A tibble: 3,365 x 9 ## daynum depth_calculated year4 sample_time water_temp pH chlorophylla ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 82 0 2012 NaN 8.32 7.59 1.06 ## 2 82 1 2012 NaN 6.54 6.56 1.24 ## 3 82 2 2012 NaN 6.41 6.27 1.35 ## 4 82 3 2012 NaN 5.92 6.10 1.81 ## 5 82 4 2012 NaN 5.74 6.10 2.07 ## 6 82 5 2012 NaN 5.66 6.37 2.31 ## 7 82 6 2012 NaN 5.51 6.34 2.63 ## 8 82 7 2012 NaN 5.30 6.34 2.86 ## 9 82 8 2012 NaN 5.14 6.32 2.95 ## 10 82 9 2012 NaN 5.03 6.38 3.31 ## # … with 3,355 more rows, and 2 more variables: opt_do2 &lt;dbl&gt;, ## # opt_dosat_raw &lt;dbl&gt; Tiene justo lo que queríamos. Vamos a representar el perfil vertical de temperatura para un día concreto. #Elegimos un día Dia_elegido &lt;- Crystal_dia %&gt;% filter(daynum == 200) #Representamos ggplot(Dia_elegido, aes(x= depth_calculated, y = water_temp))+ geom_point()+ labs(x = &quot;Profundidad (m)&quot;, y = &quot;Temperatura (ºC)&quot;) Tiene buena pinta pero es extraño. Nosotr@s estamos acostumbrados a ver los perfiles así: Figura 6.1: Representación clásica de un perfil vertical de temperatura. Pues vamos a hacer algunos cambios en el código para mejorar esto. ggplot(Dia_elegido, aes(y= depth_calculated, x = water_temp))+ geom_point()+ scale_y_reverse()+ # Invertimos la profundidad para que la parte superior sea 0 metros. scale_x_continuous(position = &quot;top&quot;)+ #Colocamos el eje arriba labs(x = &quot;Temperatura (ºC)&quot;, y = &quot;Profundidad (m)&quot;)+ theme_classic() Esto tiene mejor pinta. Prueba a usar geom_line() en lugar de geom_point(). Sucede algo extraño entorno a los 5 metros de profundidad ¿verdad? Esto sucede porque geom_line() une las observaciones ordenadas por la variable x. Prueba mejor con geom_path(). Otra opción es asignar la profundidad al eje x y cambiar los ejes (es un poco lioso, os dejo el código por si queréis indagar). ggplot(Dia_elegido, aes(x= depth_calculated, y = water_temp))+ geom_line()+ coord_flip()+ #Cambia el eje x por el y scale_x_reverse()+ # Invertimos la profundidad para que la parte superior sea 0 metros. scale_y_continuous(position = &quot;right&quot;)+ labs(x = &quot;Profundidad (m)&quot;, y = &quot;Temperatura (ºC)&quot;) Quitando esta curiosidad con respecto a como se representan las variables, ya tenemos nuestro perfil vertical de temperatura: ggplot(Dia_elegido, aes(y= depth_calculated, x = water_temp))+ geom_path(color = &quot;gray&quot;, size = 3)+ #Cambiamos un poco la estética dándole color y grosor a la línea scale_y_reverse()+ # Invertimos la profundidad para que la parte superior sea 0 metros. scale_x_continuous(position = &quot;top&quot;)+ #Colocamos el eje arriba labs(x = &quot;Temperatura (ºC)&quot;, y = &quot;Profundidad (m)&quot;)+ theme_classic() 6.1.1 Ejercicio Haz un perfil con la concentración de oxígeno disuelto y otro con el pH. 6.2 Termoclina Ahora, en base a el perfil de temperatura que hemos representado, ¿sabrías si este día el lago está estratificado? Si estuviera estratificado, ¿serías capaz de decir a que profundidad se encuentra la termoclina? A ojo podríamos acercarnos bastante pero imaginad que luego quisiéramos calcularlo para cada día… Gracias al altruismo y la ciencia colaborativa tenemos a nuestra disposición un paquete desarrollado especialmente para este tipo de cosas que nos gustan a los limnolog@s. El paquete es rLakeAnalyzer y contiene métodos estandarizados para calcular propiedades físicas del lago, como la termoclina, la estabilidad de Schmidt, etc. Para instalarlo: install.packages(\"rLakeAnalyzer\"). Si echáis un vistazo al paquete veréis un montón de funciones interesantes. Nosotros, ahora mismo, queríamos saber a que profundidad tenemos la termoclina. Para eso, vamos a pedir ayuda para aprender a usar la función ?thermo.depth(). Aquí podemos ver los argumentos que necesitamos. Por ejemplo, podemos indicarle la densidad mínima para considerar que existe termoclina o la temperatura por debajo de la cual no queremos que calcule termoclina. No vamos a reparar en estos. Sin embargo, el argumento seasonal viene por defecto como verdadero, situando la termoclina en el gradiente de densidad más profundo. Nosotros vamos a cambiarlo a FALSE. Estos son argumentos opcionales, los indispensables son un vector numérico con la temperatura del agua (wtr) y otro vector numérico con la profundidad que corresponde a cada temperatura. Estos los tenemos, así que nos podemos poner manos a la obra: #Library library(rLakeAnalyzer) #Creamos dos vectors con la información que nos pide Temp &lt;- Dia_elegido$water_temp Prof &lt;- Dia_elegido$depth_calculated #Calculamos la termoclina thermo.depth(wtr = Temp, depths = Prof, seasonal = FALSE) ## [1] 7.397819 ¡Voilá! Ya tenemos la profundidad a la que está la termoclina. Vamos a representarla: #Vamos a guardar la profundidad de la termoclina en un objeto Termoclina &lt;- thermo.depth(wtr = Temp, depths = Prof, seasonal = FALSE) ggplot(Dia_elegido, aes(y= depth_calculated, x = water_temp))+ geom_path(color = &quot;gray&quot;, size = 3)+ #Cambiamos un poco la estética dándole color y grosor a la línea geom_hline(yintercept = Termoclina)+ #Añadimos la termoclina scale_y_reverse()+ # Invertimos la profundidad para que la parte superior sea 0 metros. scale_x_continuous(position = &quot;top&quot;)+ #Colocamos el eje arriba labs(x = &quot;Temperatura (ºC)&quot;, y = &quot;Profundidad (m)&quot;)+ theme_classic() 6.3 Capas en un lago estratificado Como sabéis, cuando un lago (o un embalse) se encuentra estratificado se puede diferenciar en distintas capas. Una capa superficial, que está mezclada y en contacto con la atmósfera, el epilimnion, otra capa profunda, aislada de la superior debido al fuerte gradiente de densidad, el hipolimnion y una capa intermedia que hace de interfase entre estas dos capas, el metalimnion. Esto determinan los procesos que tendrán lugar a cada profundidad. La capa superficial al estar en contacto con la atmósfera estará bien oxigenada y dará lugar a que se desarrolle la vida aeróbica sin problemas. La capa profunda, sin embargo, puede acabar volviéndose anóxica y limitando la degradación de la materia orgánica a mecanismos de respiración anaeróbica (desnitrificación, sulfato reducción, etc) y acumulando metales que pueden ser tóxicos y comprometer su uso para abastecimiento humano. Por lo tanto, si estamos estudiando un sistema estratificado es clave reconocer y definir estás capas. Figura 6.2: Esquema de un lago estratificado. Fuente: IISD Experimental Lakes Area (IISD-ELA). Para determinar donde empiezan y donde acaban estas capas, el paquete rLakeAnalyzer dispone de un función, meta.depths(). Si leemos la información sobre la función vemos que nos devuelve el límite superior e inferior del metalimnion, que a su vez son el limite inferior del epilimnion y el límite superior del hipolimnion. Además, los argumentos obligatorios son los mismo que usamos con thermo.depth(). Así que podemos aplicarla sin problemas. meta.depths(wtr = Temp, depths = Prof, seasonal = FALSE) ## [1] 5.654340 8.370172 ¡Perfecto! Vamos a representarlo todo junto. #Guardo los límites del metalimnion metalimnion &lt;- meta.depths(wtr = Temp, depths = Prof, seasonal = FALSE) ggplot(Dia_elegido, aes(y= depth_calculated, x = water_temp))+ geom_path(color = &quot;gray&quot;, size = 3)+ #Cambiamos un poco la estética dándole color y grosor a la línea geom_hline(yintercept = Termoclina)+ #Línea en la termoclina geom_hline(yintercept = metalimnion, linetype = 2)+ #Líneas discontinuas defininedo el metalimnion scale_y_reverse()+ # Invertimos la profundidad para que la parte superior sea 0 metros. scale_x_continuous(position = &quot;top&quot;)+ #Colocamos el eje arriba labs(x = &quot;Temperatura (ºC)&quot;, y = &quot;Profundidad (m)&quot;)+ theme_classic() 6.3.1 Ejercicios Prueba a cambiar el argumento seasonal. ¿Qué sucede? ¿Podrías calcular la profundidad de la termoclina para todos los días del año en el lago Crystal? 6.4 Estabilidad La estabilidad de la columna de agua nos va a dar una idea sobre su tendencia a mezclarse o permanecer estratificada. Uno de los índices utilizados para representar la estabilidad de la masa de agua en un lago es el índice de estabilidad de Schmidt. Este indice da un valor sobre la energía que tendríamos que aplicar sobre la superficie para mezclar la columna de agua. Las unidades son, por lo tanto, J/m². El paquete rLakeAnalyzertambién nos provee de una función para calcular la estabilidad de Schmidt, schmidt.stability(). Echar una ojeada a como se usa. Si os habéis fijado, en este caso, a parte de la temperatura y la profundidad, necesitamos darle información sobre la batimetría del lago. bthA es el área que tiene cada capa a una determinada profundidad bthB. Quizás lo veis mejor en la siguiente imagen. Figura 6.3: Batimetría del lago Crystal. Pues bien, a priori, no disponemos de esta información. Quizás buscando en la base de datos de GLEON podríamos encontrar la batimetría del Lago Crystal. De hecho, está pero en un archivo .shp y deberíamos calcular el área. Todo esto se puede hacer con R (de hecho, la imagen de arriba está hecha con R)pero no vamos a abrir esa puerta ahora, ya tenemos bastante… De nuevo, el paquete rLakeAnalyzer nos proporciona la solución a nuestros problemas. Existe una función para estimar la curva área-profundidad (también conocida como curva hipsográfica) para un lago. Sólo tenemos que proporcionarle el área de la superficie del lago, la profundidad máxima y la profundidad media. Toda esta información la tenemos disponible en la página de NTL-LTER (North Temperate Lakes US Long-Term Ecological Research Network). Podéis pinchar aquí. La profundidad máxima es de 20.4 m, la superficie del lago es de 367000 m² y la profundidad media es de 11.4 m. ¡Al lío! #Estimamos la batimetría approx.bathy(Zmax = 20.4, lkeArea = 367000, Zmean = 11.4) ## depths Area.at.z ## 1 0 367000.0000 ## 2 1 331901.4802 ## 3 2 298566.7051 ## 4 3 266995.6747 ## 5 4 237188.3891 ## 6 5 209144.8481 ## 7 6 182865.0519 ## 8 7 158349.0004 ## 9 8 135596.6936 ## 10 9 114608.1315 ## 11 10 95383.3141 ## 12 11 77922.2414 ## 13 12 62224.9135 ## 14 13 48291.3303 ## 15 14 36121.4917 ## 16 15 25715.3979 ## 17 16 17073.0488 ## 18 17 10194.4444 ## 19 18 5079.5848 ## 20 19 1728.4698 ## 21 20 141.0996 Ahora ya tenemos toda la información necesaria para calcula la estabilidad de Schmidt. #Guardamos la estimación en un objeto Batimetria &lt;- approx.bathy(Zmax = 20.4, lkeArea = 367000, Zmean = 11.4) #Calculamos la estabilidad de Schmidt schmidt.stability(wtr = Temp, depths = Prof, bthA = Batimetria$Area.at.z, bthD = Batimetria$depths) ## [,1] ## [1,] 121.69 La estabilidad de Schmidt para el día 200 es de 121.69 J/m². Este número nos puede decir poco pero… ¿y si comparamos distintos días? 6.4.1 Ejercicios ¿Para qué sirve el argumento method de la función approx.bathy()? ¿Qué efecto tiene? Vamos a comparar la estabilidad de Schmidt para tres días: el primero que tenemos de 2012, el día 200 y el último que tenemos para 2012. 6.5 Series temporales Las funciones que hemos visto hasta ahora del paquete rLakeAnalyzer las hemos aplicado a perfiles vertical de un día en concreto. En uno de los ejercicios os animé a calcularais la termoclina para cada día del año 2012. Gracias al paquete dplyresta tarea no es realmente complicada. Sin embargo, el paquete rLakeAnalyzer posee una versión de cada una de la funciones que hemos visto pero que se puede aplicar a series temporales como la que nosotros tenemos. Echad un vistazo a ?ts.thermo.depth. Si os dais cuenta, el único inconveniente en que nos piden una estructura de los datos concreta. Para poder aplicarla tenemos que reorganizar la tabla. La tabla tiene que tener una columna llamada datetime con formato de fecha en lugar de día del año y una columna para cada profundidad. Lo primero que vamos a hacer es quedarnos solamente con la información del día, de la profundidad y de la temperatura del agua. #Seleccionamos las variable que nos interesan Crystal_temp &lt;- Crystal_dia %&gt;% select(daynum, depth_calculated, water_temp) Una vez que hemos seleccionado sólo lo que nos interesa, vamos a convertirlo a forma ancho usando la función spread(). #Mantenemos la fecha y convertimos la profundidad en variables (columnas) incluyendo el valor de temperatura en cada columna. Crystal_ts &lt;- Crystal_temp %&gt;% spread(key = depth_calculated, value = water_temp) Vamos a convertir el día del año en formato fecha y a cambiarle el nombre a las columnas. #Convertimos los días del año en fechas Crystal_ts &lt;- Crystal_ts %&gt;% mutate_at(vars(daynum), as.Date, origin = &quot;2012-01-01&quot;) #Cambiamos el nombre de la columna &quot;daynum&quot; a &quot;datetime&quot; Crystal_ts &lt;- Crystal_ts %&gt;% rename(datetime = daynum) #Añadimos &quot;wtr_&quot; delante del número de cada profundidad Crystal_ts &lt;- Crystal_ts %&gt;% rename_if(is.numeric, ~paste(&quot;wtr_&quot;, ., sep = &quot;&quot;)) Crystal_ts ## # A tibble: 189 x 20 ## datetime wtr_0 wtr_1 wtr_2 wtr_3 wtr_4 wtr_5 wtr_6 wtr_7 wtr_8 wtr_9 wtr_10 ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2012-03-23 8.32 6.54 6.41 5.92 5.74 5.66 5.51 5.30 5.14 5.03 4.98 ## 2 2012-03-24 NA 7.03 6.79 6.23 5.85 5.79 5.61 5.43 5.29 5.13 5.04 ## 3 2012-03-25 NA 7.78 7.12 6.32 6.06 5.90 5.78 5.67 5.42 5.28 5.11 ## 4 2012-03-26 8.20 8.11 7.99 7.07 6.04 5.88 5.66 5.60 5.43 5.26 5.06 ## 5 2012-03-27 NA 7.18 7.04 7 6.05 NA NA NA NA 5.11 5.13 ## 6 2012-03-28 NA 6.50 6.35 6.32 6.30 6.26 6.20 6.16 5.98 5.83 5.46 ## 7 2012-03-29 NA 6.36 6.34 6.32 6.31 6.31 6.28 6.12 5.81 5.74 5.69 ## 8 2012-03-30 6.02 6.60 6.28 6.25 6.22 6.18 6.16 6.15 6.04 5.98 5.86 ## 9 2012-03-31 NA 6.23 6.23 6.21 6.18 6.16 6.15 6.13 6.12 6.12 6.06 ## 10 2012-04-01 6.18 6.16 6.10 6.08 6.07 6.06 6.06 6.04 6.04 6.04 6.02 ## # … with 179 more rows, and 8 more variables: wtr_11 &lt;dbl&gt;, wtr_12 &lt;dbl&gt;, ## # wtr_13 &lt;dbl&gt;, wtr_14 &lt;dbl&gt;, wtr_15 &lt;dbl&gt;, wtr_16 &lt;dbl&gt;, wtr_17 &lt;dbl&gt;, ## # wtr_18 &lt;dbl&gt; Ya tenemos los datos ordenados para aplicar la función ts.thermo.depth(). Ahora vamos a intentar calcular la profundidad de la termoclina para cada día. termoclina_diaria &lt;- ts.thermo.depth(Crystal_ts) Vemos que tenemos muchos días con valor NA. Esto se debe a que si la función encuentra un valor de NAen el perfil de temperatura devuelve NA. Para evitar esto podemos añadir el argumento na.rm = TRUE. termoclina_diaria &lt;- ts.thermo.depth(Crystal_ts, na.rm = TRUE) Ahora vamos a guardar la información en la carpeta Datos. #Guardamos los perfiles de temperatura de cada día write_csv(Crystal_ts, &quot;Datos/Crystal_ts.csv&quot;) #Guardamos la profundidad de la termoclina write_csv(termoclina_diaria, &quot;Datos/Termoclina.csv&quot;) 6.5.1 Ejercicios Representa la profundidad de la termoclina para cada día. Calcula la estabilidad de Schmidt para todos los días. Representa el valor de la estabilidad de Schmidt para cada día. Calcula los límites del metalimnion para todos los días. "],["Contour.html", "7 Gráficas de contorno", " 7 Gráficas de contorno Por último y aprovechando que tenemos información diaria de la temperatura del lago a distintas profundidades, quizás, sería interesante realizar una gráfica de contorno del periodo estudiado. Estas gráficas son muy visuales y ayudan a entender mejor el comportamiento del lago. Las vemos a menudo en los artículos. Figura 7.1: Imagen ejemplo de gráfica de contorno extraída de Vidal et al. (2010). Existen distintos programas que permiten hacer estas gráficas como son Surfer, SigmaPlot o OceanDataView, con el inconveniente que la mayoría de ellos son privativos y de pago (OceanDataView se salva!). Además, ya estamos metidos en harina y, como hemos dicho anteriormente, R nos permite trabajar desde los datos crudos hasta la generación de gráficas e informes (estos documentos están hechos directamente desde R). Vamos a partir de la tabla de datos en formato “ancho” que creamos para calcular la profundidad de la termoclina Crystal_ts. #Cargamos tidyverse si cerramos la sesión anterior library(tidyverse) #Importamos los datos de temperatura Crystal_ts &lt;- read_csv(&quot;Datos/Crystal_ts.csv&quot;) ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## .default = col_double(), ## datetime = col_date(format = &quot;&quot;) ## ) ## ℹ Use `spec()` for the full column specifications. Cuando transformamos el objeto a formato “ancho” homogeneizamos las profundidades a las que tenemos datos de temperatura. Es decir, tenemos el mismo número de medidas y a las mismas profundidades para cada momento. Sin embargo, como los datos no estaban completos se han introducidos NAs en aquellas profundidades donde no teníamos información. Por ejemplo, en el perfil del 2012-03-27, tenemos datos de temperatura a 4 y a 9 metros pero no para las profundidades entre 5-8 m. Para solucionar esto, podemos interpolar los datos. Para ello, vamos a usar un nuevo paquete, zoo. #Cargamos el paquete. Tiene que estar previamente instalado library(zoo) ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric #Interpolamos y extrapolamos (rule = 2) la temperatura para las profundidades que nos faltan. Crystal_ts[,-1] &lt;- na.approx(Crystal_ts[,-1],rule = 2) Ahora podemos devolver los datos a su formato largo. #Cargamos el paquete tidyverse library(tidyverse) #Devolvemos la tabla al formato &quot;largo&quot; Temp_largo &lt;- gather(Crystal_ts, key = &quot;depth&quot;, value = &quot;wtemp&quot;, -datetime) #Le quitamos &quot;wtr_&quot; a la variable profundidad para que se quede sólo los números. Temp_largo &lt;- Temp_largo %&gt;% mutate(depth = parse_number(depth)) E intentamos representar. ggplot(Temp_largo, aes(x = datetime, y = depth, color = wtemp))+ geom_point() Parece que estamos bastante cerca, sin embargo, hay muchos huecos en blanco. Para solucionar esto vamos a crear una matriz y a usar una interpolación espacial multinivel b-spline para completar la información que nos falta. Para esto, usamos el paquete MBA. #Cargamos lubridate, aunque viene con tidyverse hay que &quot;llamarlo&quot; a parte. library(lubridate) #Primero tenemos que convertir las fechas en un vector numérico Temp_largo$datetime &lt;- decimal_date(Temp_largo$datetime) #Cargamos el paquete MBA, hay que instalarlo previamente. library(MBA) # Aquí creamos una matriz con mayor resolución usando una interpolación espacial multinivel b-spline Temp_mba &lt;- mba.surf(Temp_largo, no.X = 500, no.Y = 500, extend = T) #Aquí están las fecha con la nueva resolución (en este caso es mayor de la que teniamos, 500 &quot;perfiles&quot;, frente a los 189 que teníamos) head(Temp_mba$xyz.est$x) ## [1] 2012.224 2012.225 2012.226 2012.227 2012.228 2012.229 #Aquí tenemos las nuevas profundidades, 500 profundidades en lugar de las 19 que teniamos antes head(Temp_mba$xyz.est$y) ## [1] 0.00000000 0.03607214 0.07214429 0.10821643 0.14428858 0.18036072 #Estos son los datos de temperatura head(Temp_mba$xyz.est$z)[1:10] ## [1] 8.336292 8.334450 8.329062 8.320237 8.308084 8.290180 8.312388 8.310018 ## [9] 8.303618 8.293271 #Los juntamos todos Temp_prof &lt;- as.data.frame(Temp_mba$xyz.est$z) colnames(Temp_prof) &lt;- Temp_mba$xyz.est$y Temp_prof &lt;- bind_cols(date = Temp_mba$xyz.est$x, Temp_prof) #Y los volvemos al formato largo. Temp_mba &lt;- gather(Temp_prof, key = &quot;depth&quot;, value = &#39;temp&#39;, -date) %&gt;% mutate(temp = round(temp, 3)) #Ponemos la profundidad en numérico, se nos había quedado como carácter Temp_mba &lt;- Temp_mba %&gt;% mutate(depth = as.numeric(depth)) #Esta es la pinta de los datos: head(Temp_mba) ## date depth temp ## 1 2012.224 0 8.336 ## 2 2012.225 0 8.334 ## 3 2012.226 0 8.329 ## 4 2012.227 0 8.320 ## 5 2012.228 0 8.308 ## 6 2012.229 0 8.290 Ahora representamos de nuevo. ggplot(Temp_mba, aes(x = date, y = depth, color = temp))+ geom_point() ¡Mucho mejor! Vamos a cambiar algunos aspectos estéticos para que quede más resultona. #Vamos a devolverle el formato de fecha Temp_mba$date &lt;- date_decimal(Temp_mba$date) #Cargamos un paquete para usar una paleta de color má común library(colorRamps) Grafica_temp &lt;- ggplot(data = Temp_mba, aes(x = date, y = depth)) + geom_tile(aes(fill = temp)) + #Usamos esta capa que viene mejor para este tipo de gráficos pero podíamos haber usado geom_point scale_y_reverse()+ scale_fill_gradientn(colours = matlab.like2(10)) + geom_contour(aes(z = temp), binwidth = 1, colour = &quot;black&quot;, alpha = 0.2) + labs(y = &quot;Profundidad (m)&quot;, x = NULL, fill = &quot;temp. (°C)&quot;) + coord_cartesian(expand = 0) Grafica_temp Hemos cambiado el formato de la fecha, hemos invertido el eje profundidad para que se más intuitivo, hemos cambiado las etiquetas, el color y añadido unas lineas de contorno. Vamos a probar a añadirle la profundidad de la capa de mezcla. Termoclina &lt;- read_csv(&quot;Datos/Termoclina.csv&quot;) ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## datetime = col_date(format = &quot;&quot;), ## thermo.depth = col_double() ## ) Grafica_temp_zmix &lt;- Grafica_temp + geom_line(data = Termoclina, aes(x=datetime, y = thermo.depth, color = &quot;Termoclina&quot;), size = 0.2)+ scale_color_manual(values = &quot;black&quot;) + labs(color = NULL) Grafica_temp_zmix ## Error: Invalid input: time_trans works with objects of class POSIXct only ¡Vaya! Tenemos un error. Esto saca de quicio pero os iréis acostumbrando, poco a poco empezaréis a comprender que quiere decir el mensaje de error y buscar en qué os habéis equivocado. En este caso, el error nos dice que al transforma un objeto de tiempo no ha podido porque trabaja con objetos de clase POSIXct. Si os fijáis en el data.frame que usamos para hacer la gráfica de contorno (Temp_mba) la fecha está en formato POSIXct y en el data.frame de Termoclina está en formato Date. Sólo tenemos que cambiar el formato de este último y estará solucionado. Termoclina &lt;- Termoclina %&gt;% mutate(datetime = as.POSIXct(datetime)) Grafica_temp_zmix &lt;- Grafica_temp + geom_line(data = Termoclina, aes(x=datetime, y = thermo.depth, color = &quot;Termoclina&quot;), size = 0.2)+ scale_color_manual(values = &quot;black&quot;) + labs(color = NULL) Grafica_temp_zmix ## Warning: Removed 9 row(s) containing missing values (geom_path). Como vemos hay cierta oscilación en la termoclina y sobretodo en los momentos en lo que la estratificación está comenzando o se está rompiendo. A rasgos generales podemos decir que la estratificación comienza a finales de mayo y se prolonga hasta mediados de agosto. A mediados de agosto vemos que se rompe la estratificación y vuelve a estratificarse suavemente pero a mediados de septiembre el lago está totalmente mezclado con las isotermas totalmente verticales. Si queremos, para visualizar la termoclina podemos usar un suavizado: Grafica_temp_zmix &lt;- Grafica_temp + geom_smooth(data = Termoclina, aes(x=datetime, y = thermo.depth, color = &quot;Termoclina&quot;), size = 0.2, na.rm = TRUE, se = FALSE)+ scale_color_manual(values = &quot;black&quot;) + labs(color = NULL) Grafica_temp_zmix ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; Y ya la tenemos lista para exportar. Podéis guardarla en el formato que más os guste (.jpeg, .pdf, .bmp, …) simplemente cambiando el nombre con el que lo guardáis o indicándolo con el argumento device. Además también podéis fijar el ancho y el largo, así como otras opciones que podéis ver en ?ggsave(). ggsave(&quot;./Graficas/Grafica_temp.png&quot;, Grafica_temp_zmix, width = 20, height = 10, units = &quot;cm&quot;) 7.0.1 Ejercicios Añade el límite superior e inferior del metalimnion a la gráfica Gráfica_temp. Haz una gráfica de contorno para el oxígeno disuelto. Bibliografía "],["bibliografía.html", "Bibliografía", " Bibliografía "]]
